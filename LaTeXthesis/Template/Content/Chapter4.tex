\chapter{Algorithms}
\label{ch:algorithms}


In this section we  consider a greedy algorithm and some heuristics for reducing $\pi(z)$. All the heuristics use the intuition that connecting the most extreme opinions of each community can result in great reduction. 
When a new edge is introduced, the graph structure changes. This leads to changes in the opinion vector $z$.
The recomputation of the $z$ vector is expensive on time due to the computation of the inverse matrix in the $(L+I)^{-1}S$ formula.
This is why we consider two types of algorithms, those that recompute the $z$ vectors and those that do not.
All the heuristics run on $\mathcal{O}(n^2)$. This is due to the fact that they need to explore all edge combinations.

\section{Algorithms that recompute the opinion vector}
\label{sec:recomputeAlgos}

We begin with a Greedy algorithm. Greedy algorithms work in stages and during each stage a choice is made which is locally optimal.
The Greedy algorithm computes the decrease in $\pi(z)$ and selects the edge with the largest decrease every time.
\\
\\
After finding the best edge, the $Greedy$ algorithm adds this edge to the graph. This result in a change of the network structure.
Then a recomputation of the $z$ vector is happening and  the procedure is repeated.To reduce running times, we  use repeated averaging instead of computing the inverse matrix and limit the accuracy of the convergence.

\vspace{30pt}
    		\begin{algorithm}[H]
		
			\caption{Greedy}
			\label{alg:greedyAlgo}
			
			\begin{flushleft}
        				\textbf{INPUT:} Graph $G(V, E)$; $k$ number of edges to add;
				\vspace{6pt} \\
        				\textbf{OUTPUT:} A set $S$ of $k$ edges to be added to $G$ that minimize the polarization \\
				 index $\pi(z)$
			\end{flushleft}
			
			\begin{algorithmic}[1]
				\FOR {$i = 1:k \ $}
				\STATE Compute the opinion vector $z$
					\FOR { each  edge in $|V| \times |V| \textbackslash E$}
						\STATE Compute the decrease of $\pi(z)$ if edge is added to $G$
					\ENDFOR
					\STATE Select the edge with the largest decrease and add it to $G$
				\ENDFOR
				\STATE Return the set of edges that were selected
			\end{algorithmic}
		\end{algorithm}
\vspace{30pt}

\noindent A second heuristic we consider is the $FirstTopGreedy$. Let $X$ be the set of nodes of expressed opinions $\epsilon$ [-1,0) sorted by increasing order and $Y$ the set of nodes of expressed opinions $\epsilon$ (0,1] sorted by decreasing order. This heuristic use the first $k$ nodes of $X$ and $Y$, resulting in  a $k \times k$ smaller search space. This allows the $FirstTopGreedy$ to reduce the amount of time spend searching for the best edge to add. \noindent 
\\
\\
Last we consider two heuristics that choose edges based on the value of the expressed opinion of their nodes. The Distance of their opinions can be defined as $D=|z_u - z_v|$. This heuristic computes the distance between every edge candidate and then chooses to add the edge with the maximum distance.

\begin{algorithm}[htbp]
	\caption{FirstTopGreedy}
	\label{alg:kgreedy}
	
	\begin{flushleft}
        		\textbf{INPUT:} Graph $G(V, E)$; $k$ number of edges to add;\\
		$X$, the set of nodes that their expressed opinions $\epsilon$ [-1,0) sorted by increasing order\\
		$Y$, set of nodes that their expressed opinions $\epsilon$ (0,1]  sorted by decreasing order\\
		\vspace{6pt}
        		\textbf{OUTPUT:} A set $S$ of $k$ edges to be added to $G$ that minimize the polarization \\ index $\pi(z)$
	\end{flushleft}
	
	\begin{algorithmic}[1]
		\STATE $A \leftarrow $ first $k$ items of $X$
		\STATE $B \leftarrow $ first $k$ items of $Y$
		\FOR {$i = 1:k \ $}
			\STATE Compute the opinion vector $z$
			\FOR { each  edge in $|A| \times |B| \textbackslash E$}
				\STATE Compute the decrease of $\pi(z)$ if edge is added to the graph
			\ENDFOR
			\STATE Select the edge with the largest decrease and add it to $G$
		\ENDFOR
		\STATE Return the set of edges that were selected
	\end{algorithmic}
	
\end{algorithm}
		
\clearpage


\begin{algorithm}[H]
	\caption{ExpressedÎŸpinion}
	\label{alg:expressedOpinion}
	
	\begin{flushleft}
        		\textbf{INPUT:} Graph $G(V, E)$; $k$ number of edges to add\\
		\vspace{6pt}
        		\textbf{OUTPUT:} A set $S$ of $k$ edges to be added to $G$ that minimize the polarization
		\\ index $\pi(z)$
	\end{flushleft}
	
	\begin{algorithmic}[1]
		\FOR {$i = 1:k \ $}
			\STATE Compute the opinion vector $z$
			\STATE Compute the $z$ values
			\FOR { each  edge in $|V| \times |V| \textbackslash E$}
				\STATE Compute the value $D=|z_u - z_v|$.
			\ENDFOR
			\STATE Sort the distance values by decreasing order
			\STATE Add the edge with the biggest distance to $G$
		\ENDFOR
		\STATE Return the set of edges that were selected
	\end{algorithmic}
	
\end{algorithm}

\section{Algorithms that do not recompute the opinion vector}
\label{sec:norecomputeAlgo}

We continue by exploring some heuristics that do not consider the network changes and thus can run more easily in larger datasets. We will also refer to them as batch heuristics. Computing the $\pi(z)$ is an expensive operation due to the computation of the inverse matrix. At first we can see a variation of the $Greedy$ algorithm. Its implementation is similar to the $Greedy$. We compute the opinion vector only once and we sort the edges according to the decrease. Then we select the top $k$ edges.
\\
\\
We continue by using a variation of the $FirstTopGreedy$. The $FirstTopGreedyBatch$ heuristic. $FirsTopGreedy$  works exactly like $GreedyBatch$ with the difference that the opinion vector is not recomputed. Let $X$ be the set of nodes that their expressed opinions $\epsilon$ [-1,0) sorted by increasing order and $Y$ the set of nodes that their expressed opinions $\epsilon$ (0,1] sorted by decreasing order. This heuristic is taking the first $k$ nodes of $X$ and $Y$, resulting in $k \times k$ nodes.
\clearpage

\begin{algorithm}[H]
		
			\caption{GreedyBatch}
			\label{alg:greedyBatch}
			
			\begin{flushleft}
        				\textbf{INPUT:} Graph $G(V, E)$; $k$ number of edges to add;
				\vspace{6pt}\\
        				\textbf{OUTPUT:} A set $S$ of $k$ edges to be added to $G$ that minimize the polarization \\ index $\pi(z)$
			\end{flushleft}
			
			\begin{algorithmic}[1]
				\STATE Compute the $z$ values
				\FOR { each  edge in $|V| \times |V| \textbackslash E$}
					\STATE Compute the decrease of $\pi(z)$ if edge is added to $G$ 
				\ENDFOR
				\STATE Sort the values computed by decreasing order;
				\STATE Select the $k$ edges with the largest decrease and add it to $G$
				\STATE Return the set of edges that were selected
			\end{algorithmic}
		\end{algorithm}


\begin{algorithm}[H]
	\caption{FirstTopGreedyBatch}
	\label{alg:kgreedy}
	
	\begin{flushleft}
        		\textbf{INPUT:} Graph $G(V, E)$; $k$ number of edges to add;\\
		$X$, the set of nodes that their expressed opinions $\epsilon$ [-1,0) sorted by increasing order\\
		$Y$, set of nodes that their expressed opinions $\epsilon$ (0,1]  sorted by decreasing order\\
		\vspace{6pt}
        		\textbf{OUTPUT:} A set $S$ of $k$ edges to be added to $G$ that minimize the polarization\\
		 index $\pi(z)$
	\end{flushleft}
	
	\begin{algorithmic}[1]
		\STATE $A, B \leftarrow $ first $k$ items of $X$ , $Y$
				\STATE Compute the $z$ values
		\FOR { each  edge in $|A| \times |B| \textbackslash E$}
			\STATE Compute the decrease of $\pi(z)$ if edge is added to the graph
		\ENDFOR
		\STATE Sort the values computed by decreasing order
		\STATE Select the $k$ edges with the largest decrease and add it to $G$
		\STATE Return the set of edges that were selected
	\end{algorithmic}
	
\end{algorithm}
\clearpage

\section{Computing edge probabilities }		
\label{sec:computingEdge}		
\vspace{20pt}
Our objective is to predict whether there would be a link between 2 unconnected nodes. At first we will find the pairs of nodes that don't have a link between them.	
The next step is to label these pairs. This is needed for preparing a training dataset. 
The edges that are present in the graph will be labeled as $1$ (positive samples) and the unconnected node pairs as $0$ (negative samples).		
\\
\\
\noindent After the labelling we will use the node2vec algorithm to extract node features from the graph. For computing the features of an edge we can add up the features of the nodes of that pair. These features will be trained with a logistic regression model. After the model is trained we will obtain the probabilities of an edge being accepted for every edge. We use the default settings for the $Node2Vec$ algorithm and a 80/20 training/test size for the logistic regression model.
\\
\\
\noindent Computing the actual expected decrease in the polarization, and selecting the $k$ best edges is a difficult problem. Our goal is to incorporate the probabilities in the operation of the algorithms. We do not expect that the decrease in the polarization index will improve. We will do this as follows. 
\\
\\
Each algorithm computes a value $Val(u,v)$ for each candidate edge, and selects greedily edges with the best value. We will replace this value in the algorithm by $P(u,v)*Val(u,v)$. The quantity $Val(u,v)$ can be either the polarization decrease or the absolute distance of the expressed opinions of nodes $u$ and $v$. In the case that $Val(u,v)$ is the polarization decrease the product $P(u,v)*Val(u,v)$ corresponds to the expected polarization decrease.
\\
\\
In addition in section~\ref{sec:median}  we measure the median probabilities and in section~\ref{sec:all} we display the results of the heuristics and edited heuristics together including a new algorithm called $maxProb$ that chooses an edge if it is among the edges with the highest acceptance probabilities.

\clearpage

