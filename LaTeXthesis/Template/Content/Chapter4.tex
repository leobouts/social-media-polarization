\chapter{Algorithms}
\label{ch:algorithms}



\section{Intuition}
\label{sec:intuition}

To solve this problem we have to evaluate all possible edge combinations. Even for greedy heuristics we need to limit the edge candidates. The algorithm considers nodes with a high expressed value. According to our model the smallest decrease is happening when we connect a value near zero and a relatively high value.
\\
\\
We will now see why this statement holds by examining how the expressed opinion changes with an addition in the Friedkin and Johnsen model. Consider an arbitrary example with two nodes inside a network. Node $a$ has $z_a = -0.02$ and node $b$ has $z_b = 0.5$. Also for this example we assume that $w_{ii}=w_{ij}=w_{ji}=1$. 
\\
\\
If we connect these two nodes with an edge and re calculate the expressed opinions both of the $z_i$ denominators will be increased by one. This emerges from the fact that both nodes will have an additional neighbour and that all weights equal with one. The numerator of the one node $a$ will be increased by a lot and the numerator of the node $b$ will be decreased by a small value.
\\
\\
The new $z_a$ will not change a lot because the big addition in the numerator will approach the +1 addition of the denominator. On the other hand the new $z_b$ will see a big change as the numerator had a small decrease thus creating a big decrease overall for this node. We can clearly see that only one of the two nodes will amount to a big decrease. 
\\
\\
Now consider a second example of two nodes node $c$ has $z_c = -0.8$ and node $d$ has $z_d = 0.9$. After the addition node $d$ will see a big decrease because we add two conflicting values that almost neutralise each other on the numerator but the addition of the +1 on the denominator stands still. On the other hand node $c$ will also see a big decrease for the same reason. With this type of connection both of the nodes have a significant decrease.
\\


\section{Experiment by removing edges}
\label{sec:properties}
Bellow we examine the removal of edges from a social graph and their result in polarization. We also use the edge betweenness centrality. The edge betweenness centrality is defined as the number of the shortest paths that go through an edge in a graph or network.(add cite Girvan and Newman 2002). 

In the tables following Sign and Addition refer to the multiplication and the addition of the opinions of the nodes that are attached to the specific edge examined. 
\\

\begin{table}[htbp]
 \centering
 \caption{Edges with the 5 largest decrease (Karate Dataset)}
 \label{tab:edgesLargest}
 \begin{tabular}{| l || l | l | l | l |}
 \hline
  Edge & Betweeness Centrality & Polarization Decrease & Sign & Addition\\
  \hline
  \hline
  (1, 32) & $0.12725$ & $0.04669$ & - &  0\\
  \hline
  (20, 34) & $0.059384$ & $0.03470$ & - &  0\\
  \hline
  (14, 34) & $0.06782$ & $0.02924$ & - &  0\\
  \hline
  (2, 31) & $0.03228$ & $0.02505$ & - &  0\\
  \hline
  (3, 28) & $0.04119$ & $0.02068$ & - &  0\\
  \hline
 \end{tabular}
  
 \caption{Edges with the 5 smallest decrease (Karate Dataset)}
 \label{tab:edgesLargest}
 \begin{tabular}{| l || l | l | l | l |}
 \hline
  Edge & Betweeness Centrality & Polarization Decrease & Sign & Addition\\
  \hline
  \hline
  (6, 7) & $0.00297$ & $0.0$ & + &  -2\\
  \hline
  (5, 11) & $0.00297$ & $5.55111*10^{-17}$ & + &  -2\\
  \hline
  (4, 8) & $0.00336$ & $3.04869*10^{-7}$ & + &  -2\\
  \hline
  (1, 4) & $0.02049$ & $1.38023*10^{-5}$ & + &  -2\\
  \hline
  (32, 34) & $0.05339$ & $1.61826*10^{-5}$ & - &  +2\\
  \hline
  \hline
 \end{tabular}
 
\end{table}

We can clearly see that there is not a direct association between the edge betweenness centrality and the decrease in polarization. For example in the karate dataset edge (20,34) has almost the same betweenness centrality with edge (32,34). The first is among the edges that their removal contributes in one of the biggest polarization decreases while the other is among the ones with the smallest. A second thing that we can see in all three datasets is that the biggest decrease is coming from the removal of edges that connect opposing opinions.

\begin{table}[htbp]
 \centering
 \caption{Edges with the 5 largest decrease (Blogs Dataset)}
 \label{tab:edgesLargest}
 \begin{tabular}{| l || l | l | l | l |}
 \hline
  Edge & Betweenness Centrality & Polarization Decrease & Sign & Addition\\
  \hline
  \hline
  (213, 793) & $0.00219$ & $0.00091$ & - &  0\\
  \hline
  (600, 1183) & $0.00439$ & $0.00074$ & - &  0\\
  \hline
  (523, 1375) & $0.00110$ & $0.00070$ & - &  0\\
  \hline
  (325, 1159) & $0.00110$ & $0.00069$ & - &  0\\
  \hline
  (632, 1000) & $0.00110$ & $0.00069$ & - &  0\\
  \hline
 \end{tabular}
 
 
 \caption{Edges with the 5 smallest decrease (Blogs Dataset)}
 \label{tab:edgesLargest}
 \begin{tabular}{| l || l | l | l | l |}
 \hline
  Edge & Betweenness Centrality & Polarization Decrease & Sign & Addition\\
  \hline
  \hline
  (384, 385) & $9.01465*10^{-7}$ & $0.0$ & + &  -2\\
  \hline
  (301, 644) & $2.11840*10^{-5}$ & $4.64017*10^{-13}$ & + &  -2\\
  \hline
  (775, 1369) & $4.23796*10^{-5}$ & $8.28614*10^{-13}$ & + &  -2\\
  \hline
  (233, 736) & $1.37432*10^{-5}$ & $1.26054*10^{-12}$ & + &  -2\\
  \hline
  (1330, 1410) & $4.08651*10^{-5}$ & $2.12324*10^{-12}$ & + &  +2\\
  \hline
  \hline
 \end{tabular}
 
\end{table}



\begin{table}[htbp]
 \centering
 \caption{Edges with the 5 largest decrease (Books Dataset)}
 \label{tab:edgesLargest}
 \begin{tabular}{| l || l | l | l | l |}
 \hline
  Edge & Betweeness Centrality & Polarization Decrease & Sign & Addition\\
  \hline
  \hline
  (53, 76) & $0.06290$ & $0.01985$ & - &  0\\
  \hline
  (46, 102) & $0.04914$ & $0.01541$ & + &  -2\\
  \hline
  (19, 77) & $0.04367$ & $0.01458$ & + &  +2\\
  \hline
  (9, 51) & $0.02812$ & $0.01000$ & - &  0\\
  \hline
  (49, 72) & $0.06809$ & $0.00952$ & - &  0\\
  \hline
 \end{tabular}
 
 
 \caption{Edges with the 5 smallest decrease (Books Dataset)}
 \label{tab:edgesLargest}
 \begin{tabular}{| l || l | l | l | l |}
 \hline
  Edge & Betweeness Centrality & Polarization Decrease & Sign & Addition\\
  \hline
  \hline
  (13, 40) & $0.00305$ & $3.89807*10^{-9}$ & + &  +2\\
  \hline
  (35, 37) & $0.00078$ & $8.65544*10^{-9}$ & + &  +2\\
  \hline
  (88, 89) & $0.00036$ & $1.00835*10^{-8}$ & + &  -2\\
  \hline
  (65, 69) & $0.00072$ & $1.51261*10^{-8}$ & + &  -2\\
  \hline
  (35, 36) & $0.00146$ & $2.92727*10^{-8}$ & + &  +2\\
  \hline
  \hline
 \end{tabular}
 
\end{table}

\clearpage

\section{Heuristics}
\label{sec:heuristics}

In this section we  consider some heuristic algorithms for minimising $\pi(z)$. All the heuristics use the intuition that connecting the most extreme opinions of each community draw both of them into neutrality. The algorithms use two lists. One for each viewpoint sorted according to their opinion value. The naive Algorithm ~\ref{alg:naiveAlgo} stops when the first $k$ edges are found.

\vspace{10pt}

\begin{algorithm}[htbp]
	\caption{Naive minimization of $\pi(z)$}
	\label{alg:naiveAlgo}
	\begin{flushleft}
        		\textbf{INPUTS:} Graph $G$; $k$ number of edges to add;
		$X$, $Y $, the set of vertices of each viewpoint $\epsilon$ [-1,0] and [0,1] respectively.\\
		\vspace{6pt}
        		\textbf{OUTPUT:} List of $k$ edges that minimize the polarization index $\pi(z)$
	\end{flushleft}
	\begin{algorithmic}[1]
		\STATE $EdgesToAdd \leftarrow Empty List;$
		\FOR {$i = 1:n \ $}
		\STATE $Vertex \ u = X[i]$
		\FOR {$j= 1:n \ $}
		\STATE $Vertex \ v = Y[i]$
		\IF {edge$(u,v)$ does not exist in the graph}
			\STATE Compute $\pi(z)$, the decrease if the edge $(u,v)$ is added;
			\STATE Append edge $(u,v)$ to EdgesToAdd;
		\ENDIF
		\ENDFOR
		\ENDFOR
		\STATE $Sorted \leftarrow sort(EdgesToAdd)$ by the decrease of $\pi(z)$ by decreasing order;
		\STATE Return top $k$ from $Sorted$
	\end{algorithmic}
\end{algorithm}

An improvement can be done by using the $\pi(z)$ as a condition to continue. A list of $\pi(z)$ will be created with a traversal. This list will contain the polarization of each node of one of the viewpoints after adding an edge between him and the most extreme of the other.
This list can be used to break the second loop and reduce the number of computations and can be seen in ~\ref{alg:GreedyAlgo}. Even though the worst complexity is the same with ~\ref{alg:naiveAlgo} it will not reach them in an average case.

\begin{algorithm}[htbp]
	\caption{Greedy minimization of $\pi(z)$}
	\label{alg:GreedyAlgo}
	\begin{flushleft}
        		\textbf{INPUTS:} Graph $G$; $k$ number of edges to add; Number of nodes $n$;
		$X$, $Y $, the sorted set of vertices according to polarization index of each viewpoint $\epsilon$ [-1,0] and [0,1] respectively.\\
		\vspace{6pt}
        		\textbf{OUTPUT:} List of $k$ edges that minimize the polarization index $\pi(z)$
	\end{flushleft}
	\begin{algorithmic}[1]
		\STATE $EdgesToAdd \leftarrow Empty List;$
		\STATE $PolarizationFirstPass \leftarrow Empty List;$
		\STATE $Vertex \ u = X[0]$
		\FOR {$i = 1:n \ $}
		\STATE $Vertex \ v = Y[i]$
		\STATE Add edge $(u,v)$ and compute $\pi(z)$;
		\STATE Append the result to $PolarizationFirstPass$;
		\STATE Remove the edge $(u,v)$ from the graph to stay as previous;
		\ENDFOR
		
		\FOR{$i= 1:n\ $}
		\STATE $Vertex \ u = X[i]$
		\FOR {$j= 1:n \ $}
		\STATE $Vertex \ v = Y[i]$
		\STATE Compute $\pi(z)$, the decrease if the edge $(u,v)$ is added;
		\IF {$i \neq k$}
			\IF  {$\pi(z) > PolarizationFirstPass[i+1] $}
				\STATE break;
			\ENDIF
		\ENDIF
		\STATE Append edge $(u,v)$ to EdgesToAdd;
		\IF  {$SizeOf(EdgesToAdd) = k$}
			\STATE return EdgesToAdd;
		\ENDIF
		\ENDFOR
		\ENDFOR
	\end{algorithmic}
\end{algorithm}
\clearpage

We can improve further Algorithm ~\ref{alg:GreedyAlgo} by removing the need for the first pass. Instead the $\pi(z)$ a function of distance can be used as condition to continue. The same holds for the complexity with ~\ref{alg:GreedyAlgo}.


\begin{algorithm}[htbp]
	\caption{Distance minimization of $\pi(z)$}
	\label{alg:DisAlgo}
	\begin{flushleft}
        		\textbf{INPUTS:} Graph $G$; $k$ number of edges to add; Number of nodes $n$;
		$X$, $Y $, the sorted set of vertices according to polarization index of each viewpoint $\epsilon$ [-1,0] and [0,1] respectively.\\
		\vspace{6pt}
        		\textbf{OUTPUT:} List of $k$ edges that minimize the polarization index $\pi(z)$
	\end{flushleft}
	\begin{algorithmic}[1]
		\STATE $EdgesToAdd \leftarrow Empty List;$
		\FOR{$i= 1:n\ $}
		\STATE $Vertex \ u = X[i]$
		\FOR {$j= 1:n \ $}
		\STATE $Vertex \ v = Y[i]$
		\IF {$i \neq k$}
			\IF {$Abs(v)+Abs(u) \leqslant Abs(X[i+1]) + Abs(Y[0])$}
				\STATE continue;
			\ENDIF
		\ENDIF
		\STATE Compute $\pi(z)$, the decrease if the edge $(u,v)$ is added;
		\STATE Append edge $(u,v)$ to EdgesToAdd;
		\IF  {$SizeOf(EdgesToAdd) = k$}
			\STATE return EdgesToAdd;
		\ENDIF
		\ENDFOR
		\ENDFOR
	\end{algorithmic}
\end{algorithm}

\clearpage

Bellow we can see the results of these algorithms in two datasets.

\begin{table}[htbp]
 \centering
 \caption{Heuristics algorithm comparison}
 \label{tab:heuristics}
 \begin{tabular}{| l || l | l | l | l |}
 \hline
  Algorithm & Dataset & Before & After & time\\
  \hline
  \hline
  Naive & Karate & $0.35857$ & 0.23116 &  0.93457\\
  \hline
  Merge & Karate & $0.35857$ & 0.15205 &  0.02955\\
  \hline
  Distance & Karate & $0.35857$ & 0.13423 &  0.00262\\
  \hline
  \hline
  Naive & Books & $0.44046$ & 0.35138 &  30.53548\\
  \hline
  Merge & Books & $0.44046$ & 0.34692 &  0.29411\\
  \hline
  Distance & Books & $0.44046$ & 0.34719 &  0.01033\\
  \hline
 \end{tabular}
 
\end{table}

